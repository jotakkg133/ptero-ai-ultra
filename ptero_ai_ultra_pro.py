#!/usr/bin/env python3
"""
PTERO-AI ULTRA PRO v2.0
Sistema de IA Multi-Camadas com InteligÃªncia AvanÃ§ada
Desenvolvido para ser EXTREMAMENTE ESPERTO e NUNCA quebrar nada
"""

import os
import sys
import json
import shutil
import subprocess
import hashlib
import tarfile
import re
import ast
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from enum import Enum
import google.generativeai as genai


class SecurityLevel(Enum):
    """NÃ­veis de seguranÃ§a para operaÃ§Ãµes"""
    SAFE = "safe"           # 100% seguro
    LOW_RISK = "low_risk"   # Risco baixo
    MEDIUM = "medium"       # Requer atenÃ§Ã£o
    HIGH = "high"           # Requer confirmaÃ§Ã£o
    CRITICAL = "critical"   # Requer mÃºltiplas confirmaÃ§Ãµes


class OperationType(Enum):
    """Tipos de operaÃ§Ã£o"""
    READ = "read"
    ANALYZE = "analyze"
    EDIT = "edit"
    CREATE = "create"
    DELETE = "delete"
    COMMAND = "command"
    SYSTEM = "system"


@dataclass
class ValidationResult:
    """Resultado de validaÃ§Ã£o"""
    valid: bool
    security_level: SecurityLevel
    risks: List[str] = field(default_factory=list)
    suggestions: List[str] = field(default_factory=list)
    estimated_impact: str = "low"
    dependencies: List[str] = field(default_factory=list)
    tests_required: bool = False
    rollback_plan: Optional[str] = None


@dataclass
class AIDecision:
    """DecisÃ£o tomada pela IA"""
    action: str
    reasoning: str
    confidence: float  # 0.0 a 1.0
    alternatives: List[str] = field(default_factory=list)
    validation: Optional[ValidationResult] = None
    execution_plan: List[str] = field(default_factory=list)


class ContextCache:
    """Cache inteligente de contexto"""
    
    def __init__(self, cache_dir: Path):
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.memory = {}
        self.load_cache()
    
    def load_cache(self):
        """Carrega cache do disco"""
        cache_file = self.cache_dir / 'context_cache.json'
        if cache_file.exists():
            try:
                with open(cache_file) as f:
                    self.memory = json.load(f)
            except:
                self.memory = {}
    
    def save_cache(self):
        """Salva cache no disco"""
        cache_file = self.cache_dir / 'context_cache.json'
        with open(cache_file, 'w') as f:
            json.dump(self.memory, indent=2, fp=f)
    
    def get(self, key: str) -> Optional[Any]:
        """ObtÃ©m valor do cache"""
        entry = self.memory.get(key)
        if entry:
            # Verificar se cache ainda Ã© vÃ¡lido (24h)
            timestamp = entry.get('timestamp', 0)
            if time.time() - timestamp < 86400:  # 24 horas
                return entry.get('data')
        return None
    
    def set(self, key: str, value: Any):
        """Define valor no cache"""
        self.memory[key] = {
            'data': value,
            'timestamp': time.time()
        }
        self.save_cache()


class AIValidator:
    """Sistema de validaÃ§Ã£o inteligente em mÃºltiplas camadas"""
    
    def __init__(self, model):
        self.model = model
    
    def validate_code_change(self, file_path: str, old_code: str, new_code: str) -> ValidationResult:
        """Valida mudanÃ§a de cÃ³digo com anÃ¡lise profunda"""
        
        risks = []
        suggestions = []
        dependencies = []
        
        # Camada 1: AnÃ¡lise sintÃ¡tica
        if file_path.endswith(('.py', '.js', '.jsx', '.ts', '.tsx')):
            syntax_valid = self._check_syntax(file_path, new_code)
            if not syntax_valid:
                risks.append("Erro de sintaxe detectado")
                return ValidationResult(
                    valid=False,
                    security_level=SecurityLevel.HIGH,
                    risks=risks
                )
        
        # Camada 2: AnÃ¡lise de seguranÃ§a
        security_issues = self._analyze_security(new_code)
        if security_issues:
            risks.extend(security_issues)
        
        # Camada 3: AnÃ¡lise de dependÃªncias
        deps = self._extract_dependencies(new_code)
        dependencies.extend(deps)
        
        # Camada 4: AnÃ¡lise de impacto
        impact = self._analyze_impact(old_code, new_code)
        
        # Camada 5: ValidaÃ§Ã£o por IA
        ai_validation = self._ai_deep_validation(file_path, old_code, new_code)
        
        # Determinar nÃ­vel de seguranÃ§a
        security_level = self._calculate_security_level(risks, impact, ai_validation)
        
        return ValidationResult(
            valid=len(risks) == 0 or security_level != SecurityLevel.CRITICAL,
            security_level=security_level,
            risks=risks,
            suggestions=suggestions,
            estimated_impact=impact,
            dependencies=dependencies,
            tests_required=impact in ['medium', 'high'],
            rollback_plan=self._generate_rollback_plan(file_path)
        )
    
    def _check_syntax(self, file_path: str, code: str) -> bool:
        """Verifica sintaxe do cÃ³digo"""
        try:
            if file_path.endswith('.py'):
                ast.parse(code)
            elif file_path.endswith(('.js', '.jsx', '.ts', '.tsx')):
                # VerificaÃ§Ã£o bÃ¡sica de brackets
                if code.count('{') != code.count('}'):
                    return False
                if code.count('(') != code.count(')'):
                    return False
                if code.count('[') != code.count(']'):
                    return False
            return True
        except:
            return False
    
    def _analyze_security(self, code: str) -> List[str]:
        """Analisa questÃµes de seguranÃ§a"""
        issues = []
        
        # PadrÃµes perigosos
        dangerous_patterns = [
            (r'eval\s*\(', "Uso de eval() detectado - PERIGOSO"),
            (r'exec\s*\(', "Uso de exec() detectado - PERIGOSO"),
            (r'__import__\s*\(', "Import dinÃ¢mico detectado"),
            (r'subprocess\.call\s*\(.*shell\s*=\s*True', "Shell=True em subprocess - RISCO"),
            (r'password\s*=\s*["\'].*["\']', "Senha em texto plano detectada"),
            (r'api[_-]?key\s*=\s*["\'].*["\']', "API key em texto plano detectada"),
        ]
        
        for pattern, message in dangerous_patterns:
            if re.search(pattern, code, re.IGNORECASE):
                issues.append(message)
        
        return issues
    
    def _extract_dependencies(self, code: str) -> List[str]:
        """Extrai dependÃªncias do cÃ³digo"""
        deps = []
        
        # Python imports
        for match in re.finditer(r'^import\s+(\S+)', code, re.MULTILINE):
            deps.append(match.group(1))
        for match in re.finditer(r'^from\s+(\S+)\s+import', code, re.MULTILINE):
            deps.append(match.group(1))
        
        # JavaScript/TypeScript imports
        for match in re.finditer(r'import\s+.*?\s+from\s+["\'](.+?)["\']', code):
            deps.append(match.group(1))
        
        return list(set(deps))
    
    def _analyze_impact(self, old_code: str, new_code: str) -> str:
        """Analisa impacto da mudanÃ§a"""
        
        # Calcular diferenÃ§a
        old_lines = old_code.split('\n')
        new_lines = new_code.split('\n')
        
        lines_added = len(new_lines) - len(old_lines)
        lines_changed = sum(1 for old, new in zip(old_lines, new_lines) if old != new)
        
        total_change = abs(lines_added) + lines_changed
        
        if total_change < 5:
            return "low"
        elif total_change < 20:
            return "medium"
        else:
            return "high"
    
    def _ai_deep_validation(self, file_path: str, old_code: str, new_code: str) -> Dict:
        """ValidaÃ§Ã£o profunda usando IA"""
        
        prompt = f"""Analise esta mudanÃ§a de cÃ³digo como um especialista em seguranÃ§a:

ARQUIVO: {file_path}

CÃ“DIGO ANTIGO (primeiras 50 linhas):
{chr(10).join(old_code.split(chr(10))[:50])}

CÃ“DIGO NOVO (primeiras 50 linhas):
{chr(10).join(new_code.split(chr(10))[:50])}

Analise:
1. Potenciais bugs
2. Problemas de seguranÃ§a
3. Impacto em performance
4. Quebra de compatibilidade
5. Boas prÃ¡ticas violadas

Responda em JSON:
{{
  "bugs_potential": [],
  "security_issues": [],
  "performance_impact": "none|low|medium|high",
  "breaking_changes": bool,
  "best_practices_violated": [],
  "recommendation": "approve|review|reject",
  "confidence": 0.0-1.0
}}
"""
        
        try:
            response = self.model.generate_content(prompt)
            text = response.text
            
            # Extrair JSON
            start = text.find('{')
            end = text.rfind('}') + 1
            
            if start >= 0 and end > start:
                return json.loads(text[start:end])
        except:
            pass
        
        return {
            "recommendation": "review",
            "confidence": 0.5
        }
    
    def _calculate_security_level(self, risks: List[str], impact: str, ai_validation: Dict) -> SecurityLevel:
        """Calcula nÃ­vel de seguranÃ§a geral"""
        
        # Score system
        score = 0
        
        # Riscos crÃ­ticos
        critical_keywords = ['PERIGOSO', 'CRÃTICO', 'senha', 'password', 'api key']
        for risk in risks:
            if any(kw in risk for kw in critical_keywords):
                score += 10
            else:
                score += 2
        
        # Impacto
        impact_scores = {'low': 0, 'medium': 3, 'high': 6}
        score += impact_scores.get(impact, 0)
        
        # RecomendaÃ§Ã£o da IA
        ai_rec = ai_validation.get('recommendation', 'review')
        if ai_rec == 'reject':
            score += 8
        elif ai_rec == 'review':
            score += 3
        
        # Converter score em nÃ­vel
        if score >= 15:
            return SecurityLevel.CRITICAL
        elif score >= 10:
            return SecurityLevel.HIGH
        elif score >= 5:
            return SecurityLevel.MEDIUM
        elif score >= 2:
            return SecurityLevel.LOW_RISK
        else:
            return SecurityLevel.SAFE
    
    def _generate_rollback_plan(self, file_path: str) -> str:
        """Gera plano de rollback"""
        return f"Restaurar {file_path} do backup mais recente usando comando 'restore'"


class CodeAnalyzer:
    """Analisador profundo de cÃ³digo - LÃŠ e ENTENDE completamente"""
    
    def __init__(self, model):
        self.model = model
    
    def deep_analyze_file(self, file_path: str) -> Dict:
        """AnÃ¡lise PROFUNDA de um arquivo - entende TUDO"""
        
        if not Path(file_path).exists():
            return {'error': 'Arquivo nÃ£o encontrado'}
        
        print(f"\nğŸ“– LENDO E ANALISANDO: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            return {'error': f'Erro ao ler arquivo: {e}'}
        
        # Metadados bÃ¡sicos
        lines = content.split('\n')
        total_lines = len(lines)
        
        print(f"   ğŸ“„ Arquivo: {total_lines} linhas")
        
        # Detectar linguagem
        language = self._detect_language(file_path)
        print(f"   ğŸ”¤ Linguagem: {language}")
        
        # AnÃ¡lise sintÃ¡tica bÃ¡sica
        structure = self._analyze_structure(content, language)
        print(f"   ğŸ—ï¸  Estrutura: {structure['summary']}")
        
        # ANÃLISE PROFUNDA COM IA
        print(f"   ğŸ§  IA analisando profundamente...")
        
        deep_analysis = self._ai_deep_read(file_path, content, language, structure)
        
        print(f"   âœ“ AnÃ¡lise completa!")
        
        return {
            'file_path': file_path,
            'language': language,
            'total_lines': total_lines,
            'structure': structure,
            'content': content,
            'deep_analysis': deep_analysis,
            'timestamp': datetime.now().isoformat()
        }
    
    def _detect_language(self, file_path: str) -> str:
        """Detecta linguagem do arquivo"""
        ext = Path(file_path).suffix.lower()
        
        lang_map = {
            '.py': 'Python',
            '.js': 'JavaScript',
            '.jsx': 'React JSX',
            '.ts': 'TypeScript',
            '.tsx': 'React TypeScript',
            '.php': 'PHP',
            '.css': 'CSS',
            '.html': 'HTML',
            '.json': 'JSON',
            '.md': 'Markdown'
        }
        
        return lang_map.get(ext, 'Unknown')
    
    def _analyze_structure(self, content: str, language: str) -> Dict:
        """Analisa estrutura do cÃ³digo"""
        
        structure = {
            'functions': [],
            'classes': [],
            'imports': [],
            'exports': [],
            'components': [],
            'hooks': [],
            'summary': ''
        }
        
        lines = content.split('\n')
        
        if language == 'Python':
            # FunÃ§Ãµes
            for i, line in enumerate(lines, 1):
                if line.strip().startswith('def '):
                    func_name = line.strip().split('(')[0].replace('def ', '')
                    structure['functions'].append({
                        'name': func_name,
                        'line': i
                    })
                elif line.strip().startswith('class '):
                    class_name = line.strip().split('(')[0].replace('class ', '').replace(':', '')
                    structure['classes'].append({
                        'name': class_name,
                        'line': i
                    })
                elif line.strip().startswith(('import ', 'from ')):
                    structure['imports'].append(line.strip())
        
        elif language in ['JavaScript', 'TypeScript', 'React JSX', 'React TypeScript']:
            for i, line in enumerate(lines, 1):
                stripped = line.strip()
                
                # FunÃ§Ãµes
                if 'function ' in stripped or '=>' in stripped:
                    if 'function ' in stripped:
                        func_match = re.search(r'function\s+(\w+)', stripped)
                        if func_match:
                            structure['functions'].append({
                                'name': func_match.group(1),
                                'line': i
                            })
                    elif 'const ' in stripped and '=>' in stripped:
                        func_match = re.search(r'const\s+(\w+)\s*=', stripped)
                        if func_match:
                            structure['functions'].append({
                                'name': func_match.group(1),
                                'line': i
                            })
                
                # Classes/Components
                if 'class ' in stripped:
                    class_match = re.search(r'class\s+(\w+)', stripped)
                    if class_match:
                        structure['classes'].append({
                            'name': class_match.group(1),
                            'line': i
                        })
                
                # Componentes React
                if re.search(r'(const|function)\s+([A-Z]\w+)', stripped):
                    comp_match = re.search(r'(const|function)\s+([A-Z]\w+)', stripped)
                    if comp_match:
                        structure['components'].append({
                            'name': comp_match.group(2),
                            'line': i
                        })
                
                # Hooks React
                if 'useState' in stripped or 'useEffect' in stripped or 'use' in stripped:
                    hook_match = re.search(r'use\w+', stripped)
                    if hook_match:
                        if hook_match.group() not in structure['hooks']:
                            structure['hooks'].append(hook_match.group())
                
                # Imports
                if stripped.startswith('import '):
                    structure['imports'].append(stripped)
                
                # Exports
                if stripped.startswith('export '):
                    structure['exports'].append(stripped)
        
        # Gerar summary
        parts = []
        if structure['classes']:
            parts.append(f"{len(structure['classes'])} classes")
        if structure['components']:
            parts.append(f"{len(structure['components'])} components")
        if structure['functions']:
            parts.append(f"{len(structure['functions'])} functions")
        if structure['hooks']:
            parts.append(f"{len(structure['hooks'])} hooks")
        
        structure['summary'] = ', '.join(parts) if parts else 'cÃ³digo simples'
        
        return structure
    
    def _ai_deep_read(self, file_path: str, content: str, language: str, structure: Dict) -> Dict:
        """IA lÃª e ENTENDE profundamente o cÃ³digo"""
        
        # Limitar conteÃºdo para nÃ£o estourar token limit
        content_preview = '\n'.join(content.split('\n')[:200])  # Primeiras 200 linhas
        
        prompt = f"""VocÃª Ã© um especialista em {language} analisando cÃ³digo em profundidade.

ARQUIVO: {file_path}
LINGUAGEM: {language}
ESTRUTURA DETECTADA:
- Classes: {[c['name'] for c in structure['classes']]}
- Componentes: {[c['name'] for c in structure['components']]}
- FunÃ§Ãµes: {[f['name'] for f in structure['functions']]}
- Hooks: {structure['hooks']}

CÃ“DIGO (primeiras 200 linhas):
```{language.lower()}
{content_preview}
```

ANALISE PROFUNDAMENTE:

1. **PropÃ³sito do Arquivo**
   - O que este arquivo faz?
   - Qual sua responsabilidade?

2. **Estrutura e OrganizaÃ§Ã£o**
   - Como estÃ¡ organizado?
   - Segue boas prÃ¡ticas?

3. **DependÃªncias e Imports**
   - Quais bibliotecas usa?
   - HÃ¡ dependÃªncias circulares?

4. **Componentes/Classes Principais**
   - O que cada um faz?
   - Como se relacionam?

5. **Estado e Dados**
   - Como gerencia estado?
   - Quais dados manipula?

6. **LÃ³gica de NegÃ³cio**
   - Principais funÃ§Ãµes e fluxos
   - ValidaÃ§Ãµes e regras

7. **Pontos de AtenÃ§Ã£o**
   - CÃ³digo complexo ou frÃ¡gil
   - Ãreas que requerem cuidado
   - PossÃ­veis bugs

8. **Como Editar com SeguranÃ§a**
   - Onde Ã© seguro adicionar cÃ³digo
   - O que NÃƒO deve ser tocado
   - DependÃªncias a considerar

Responda em JSON:
{{
  "purpose": "propÃ³sito principal",
  "main_components": ["lista de componentes principais"],
  "key_functions": ["funÃ§Ãµes crÃ­ticas"],
  "state_management": "como gerencia estado",
  "dependencies": ["dependÃªncias importantes"],
  "complexity_level": "low|medium|high",
  "safe_edit_zones": ["Ã¡reas seguras para editar"],
  "danger_zones": ["Ã¡reas PERIGOSAS - nÃ£o tocar"],
  "recommendations": ["recomendaÃ§Ãµes para ediÃ§Ã£o"],
  "understanding_score": 0.0-1.0
}}
"""
        
        try:
            response = self.model.generate_content(prompt)
            text = response.text
            
            # Extrair JSON
            start = text.find('{')
            end = text.rfind('}') + 1
            
            if start >= 0 and end > start:
                analysis = json.loads(text[start:end])
                
                # Adicionar insights textuais
                analysis['full_text'] = text
                
                return analysis
        except Exception as e:
            print(f"   âš ï¸  Erro na anÃ¡lise IA: {e}")
        
        return {
            'purpose': 'NÃ£o foi possÃ­vel determinar',
            'understanding_score': 0.3
        }


class SmartAIEngine:
    """Motor de IA com mÃºltiplas camadas de inteligÃªncia"""
    
    def __init__(self, api_key: str, context_cache: ContextCache):
        genai.configure(api_key=api_key)
        
        # Modelo principal (raciocÃ­nio)
        self.main_model = genai.GenerativeModel(
            'gemini-pro',
            generation_config={
                'temperature': 0.2,
                'top_p': 0.8,
                'top_k': 40,
                'max_output_tokens': 8192
            }
        )
        
        # Modelo de validaÃ§Ã£o (crÃ­tico)
        self.validator_model = genai.GenerativeModel(
            'gemini-pro',
            generation_config={
                'temperature': 0.1,  # Muito conservador
                'top_p': 0.7,
                'top_k': 20
            }
        )
        
        self.cache = context_cache
        self.validator = AIValidator(self.validator_model)
        self.code_analyzer = CodeAnalyzer(self.main_model)  # NOVO!
        self.chat = self.main_model.start_chat(history=[])
        self.decision_history = []
        self.file_knowledge = {}  # Cache de conhecimento de arquivos
    
    def analyze_request(self, user_request: str, system_context: Dict) -> AIDecision:
        """Analisa requisiÃ§Ã£o do usuÃ¡rio com inteligÃªncia avanÃ§ada"""
        
        # Verificar cache
        cache_key = hashlib.md5(user_request.encode()).hexdigest()
        cached = self.cache.get(f"request_{cache_key}")
        
        if cached:
            print("ğŸ’¾ Resposta recuperada do cache")
            return AIDecision(**cached)
        
        # AnÃ¡lise em mÃºltiplas etapas
        print("ğŸ§  Analisando requisiÃ§Ã£o em mÃºltiplas camadas...")
        
        # Etapa 1: CompreensÃ£o da intenÃ§Ã£o
        intent = self._analyze_intent(user_request)
        print(f"   1/6 IntenÃ§Ã£o: {intent['type']}")
        
        # Etapa 2: Identificar arquivos alvos
        target_files = self._identify_target_files(user_request, intent)
        print(f"   2/6 Arquivos alvo: {len(target_files)}")
        
        # Etapa 2.5: ANÃLISE PROFUNDA DOS ARQUIVOS (NOVO!)
        files_analysis = {}
        if target_files:
            print(f"\n   ğŸ” ANALISANDO ARQUIVOS PROFUNDAMENTE...")
            for file_path in target_files:
                if file_path not in self.file_knowledge:
                    analysis = self.code_analyzer.deep_analyze_file(file_path)
                    self.file_knowledge[file_path] = analysis
                    files_analysis[file_path] = analysis
                else:
                    print(f"   ğŸ’¾ {file_path} jÃ¡ analisado (cache)")
                    files_analysis[file_path] = self.file_knowledge[file_path]
        
        # Etapa 3: AnÃ¡lise de contexto (agora com conhecimento dos arquivos)
        context_analysis = self._analyze_context(user_request, system_context, files_analysis)
        print(f"   3/6 Contexto: {len(context_analysis['relevant_files'])} arquivos relevantes")
        
        # Etapa 4: GeraÃ§Ã£o de plano de execuÃ§Ã£o (com conhecimento profundo)
        execution_plan = self._generate_execution_plan_smart(
            user_request, intent, context_analysis, files_analysis
        )
        print(f"   4/6 Plano: {len(execution_plan)} etapas")
        
        # Etapa 5: ValidaÃ§Ã£o de seguranÃ§a
        validation = self._validate_plan(execution_plan, system_context)
        print(f"   5/6 SeguranÃ§a: {validation.security_level.value}")
        
        # Etapa 6: GeraÃ§Ã£o de alternativas
        alternatives = self._generate_alternatives(user_request, execution_plan)
        print(f"   6/6 Alternativas: {len(alternatives)}")
        
        # Criar decisÃ£o
        decision = AIDecision(
            action=intent['type'],
            reasoning=intent['reasoning'],
            confidence=intent['confidence'],
            alternatives=alternatives,
            validation=validation,
            execution_plan=execution_plan
        )
        
        # Salvar no cache
        self.cache.set(f"request_{cache_key}", decision.__dict__)
        
        # Adicionar ao histÃ³rico
        self.decision_history.append({
            'timestamp': datetime.now().isoformat(),
            'request': user_request,
            'decision': decision.__dict__,
            'files_analyzed': list(files_analysis.keys())
        })
        
        return decision
    
    def _identify_target_files(self, user_request: str, intent: Dict) -> List[str]:
        """Identifica quais arquivos serÃ£o afetados"""
        
        target_files = []
        
        # Extrair menÃ§Ãµes diretas de arquivos
        file_patterns = re.findall(r'[\w/\.-]+\.(tsx?|jsx?|php|py|css|json)', user_request, re.IGNORECASE)
        
        for file_pattern in file_patterns:
            # Buscar arquivo no sistema
            possible_paths = [
                f"/var/www/pterodactyl/{file_pattern}",
                f"/var/www/pterodactyl/resources/scripts/{file_pattern}",
                f"/var/www/pterodactyl/resources/scripts/components/{file_pattern}",
                f"/var/www/pterodactyl/app/Http/Controllers/{file_pattern}",
            ]
            
            for path in possible_paths:
                if Path(path).exists():
                    target_files.append(path)
                    break
        
        # Se nÃ£o encontrou arquivo explÃ­cito, usar intent
        if not target_files and 'target' in intent:
            # Buscar baseado no alvo do intent
            target = intent['target']
            print(f"   ğŸ” Buscando arquivo para: {target}")
        
        return target_files
    
    def _analyze_intent(self, user_request: str) -> Dict:
        """Analisa a intenÃ§Ã£o do usuÃ¡rio"""
        
        prompt = f"""Como especialista em anÃ¡lise de intenÃ§Ãµes, determine o que o usuÃ¡rio quer fazer:

REQUISIÃ‡ÃƒO: "{user_request}"

Responda em JSON:
{{
  "type": "edit|create|delete|analyze|fix|optimize|other",
  "target": "arquivo ou componente alvo",
  "reasoning": "explicaÃ§Ã£o da intenÃ§Ã£o",
  "confidence": 0.0-1.0,
  "requires_files": ["lista", "de", "arquivos"],
  "action_verb": "verbo principal da aÃ§Ã£o"
}}
"""
        
        try:
            response = self.main_model.generate_content(prompt)
            text = response.text
            start = text.find('{')
            end = text.rfind('}') + 1
            
            if start >= 0 and end > start:
                return json.loads(text[start:end])
        except Exception as e:
            print(f"   Erro na anÃ¡lise de intenÃ§Ã£o: {e}")
        
        return {
            "type": "other",
            "target": "unknown",
            "reasoning": "NÃ£o foi possÃ­vel determinar a intenÃ§Ã£o",
            "confidence": 0.3,
            "requires_files": [],
            "action_verb": "process"
        }
    
    def _analyze_context(self, user_request: str, system_context: Dict, files_analysis: Dict = None) -> Dict:
        """Analisa contexto necessÃ¡rio (com conhecimento profundo dos arquivos)"""
        
        # Extrair arquivos mencionados
        mentioned_files = re.findall(r'[\w/\.-]+\.(tsx?|jsx?|php|py|css|json)', user_request, re.IGNORECASE)
        
        # Buscar arquivos similares no sistema
        relevant_files = []
        
        ptero_structure = system_context.get('pterodactyl', {}).get('structure', {})
        
        def search_files(structure, path=''):
            for name, info in structure.items():
                current_path = f"{path}/{name}" if path else name
                if info.get('type') == 'file':
                    # Verificar se arquivo Ã© relevante
                    if any(mentioned in current_path for mentioned in mentioned_files):
                        relevant_files.append(current_path)
                elif info.get('type') == 'directory':
                    search_files(info.get('children', {}), current_path)
        
        search_files(ptero_structure)
        
        return {
            'mentioned_files': mentioned_files,
            'relevant_files': relevant_files,
            'system_state': system_context,
            'files_deep_knowledge': files_analysis or {}  # NOVO!
        }
    
    def _generate_execution_plan_smart(self, user_request: str, intent: Dict, 
                                      context: Dict, files_analysis: Dict) -> List[str]:
        """Gera plano de execuÃ§Ã£o COM conhecimento profundo dos arquivos"""
        
        # Preparar contexto enriquecido
        files_context = ""
        for file_path, analysis in files_analysis.items():
            deep = analysis.get('deep_analysis', {})
            files_context += f"\n\nARQUIVO: {file_path}"
            files_context += f"\n  PropÃ³sito: {deep.get('purpose', 'N/A')}"
            files_context += f"\n  Complexidade: {deep.get('complexity_level', 'N/A')}"
            files_context += f"\n  Zonas seguras: {deep.get('safe_edit_zones', [])}"
            files_context += f"\n  Zonas perigosas: {deep.get('danger_zones', [])}"
            files_context += f"\n  RecomendaÃ§Ãµes: {deep.get('recommendations', [])}"
            files_context += f"\n  Score de entendimento: {deep.get('understanding_score', 0)*100:.0f}%"
        
        prompt = f"""Como arquiteto de software EXPERIENTE que ENTENDEU PROFUNDAMENTE o cÃ³digo, 
crie um plano de execuÃ§Ã£o DETALHADO e SEGURO:

REQUISIÃ‡ÃƒO: "{user_request}"

INTENÃ‡ÃƒO DETECTADA:
{json.dumps(intent, indent=2)}

CONHECIMENTO PROFUNDO DOS ARQUIVOS:
{files_context}

CONTEXTO ADICIONAL:
- Arquivos mencionados: {context['mentioned_files']}
- Arquivos relevantes: {context['relevant_files']}

Com base no seu ENTENDIMENTO PROFUNDO do cÃ³digo, crie um plano que:

1. RESPEITE a estrutura existente
2. EVITE as zonas perigosas identificadas
3. USE as zonas seguras para ediÃ§Ã£o
4. SIGA as recomendaÃ§Ãµes especÃ­ficas
5. PRESERVE a lÃ³gica de negÃ³cio
6. MANTENHA as dependÃªncias intactas
7. GARANTA que mudanÃ§as nÃ£o quebrem nada

Considere:
- Backup necessÃ¡rio
- ValidaÃ§Ãµes necessÃ¡rias
- Testes a executar
- Ordem correta de execuÃ§Ã£o
- Pontos de rollback
- Impacto em outros componentes

Responda em JSON:
{{
  "steps": [
    {{
      "order": 1,
      "action": "descriÃ§Ã£o detalhada da aÃ§Ã£o",
      "type": "backup|validate|edit|test|deploy",
      "files": ["arquivos envolvidos"],
      "reasoning": "por que este passo Ã© necessÃ¡rio",
      "safe_zone": "zona segura sendo usada",
      "reversible": true|false,
      "risk_level": "low|medium|high"
    }}
  ],
  "estimated_time": "tempo estimado",
  "dependencies": ["dependÃªncias necessÃ¡rias"],
  "rollback_strategy": "estratÃ©gia detalhada de rollback",
  "impact_assessment": "avaliaÃ§Ã£o de impacto baseada no conhecimento",
  "confidence": 0.0-1.0
}}
"""
        
        try:
            response = self.main_model.generate_content(prompt)
            text = response.text
            start = text.find('{')
            end = text.rfind('}') + 1
            
            if start >= 0 and end > start:
                plan_data = json.loads(text[start:end])
                
                # Mostrar raciocÃ­nio
                if plan_data.get('confidence', 0) > 0.8:
                    print(f"\n   âœ“ Plano gerado com alta confianÃ§a ({plan_data['confidence']*100:.0f}%)")
                
                return [step['action'] for step in plan_data.get('steps', [])]
        except Exception as e:
            print(f"   âš ï¸  Erro ao gerar plano: {e}")
        
        return ["Criar backup", "Analisar requisiÃ§Ã£o", "Executar mudanÃ§a", "Validar resultado"]
    
    def _validate_plan(self, execution_plan: List[str], system_context: Dict) -> ValidationResult:
        """Valida plano de execuÃ§Ã£o"""
        
        risks = []
        
        # Verificar se backup estÃ¡ incluÃ­do
        if not any('backup' in step.lower() for step in execution_plan):
            risks.append("Plano nÃ£o inclui etapa de backup")
        
        # Verificar se hÃ¡ validaÃ§Ã£o
        if not any('valid' in step.lower() or 'test' in step.lower() for step in execution_plan):
            risks.append("Plano nÃ£o inclui validaÃ§Ã£o/testes")
        
        # AnÃ¡lise por IA
        validation_prompt = f"""Como auditor de seguranÃ§a, avalie este plano:

PLANO:
{json.dumps(execution_plan, indent=2)}

CONTEXTO DO SISTEMA:
- Pterodactyl instalado: {system_context.get('pterodactyl', {}).get('installed', False)}
- ServiÃ§os ativos: {len(system_context.get('services', []))}

Responda em JSON:
{{
  "safe": true|false,
  "risks": ["lista de riscos"],
  "missing_steps": ["etapas ausentes importantes"],
  "recommendation": "approve|modify|reject"
}}
"""
        
        try:
            response = self.validator_model.generate_content(validation_prompt)
            text = response.text
            start = text.find('{')
            end = text.rfind('}') + 1
            
            if start >= 0 and end > start:
                validation_data = json.loads(text[start:end])
                risks.extend(validation_data.get('risks', []))
        except:
            pass
        
        # Determinar nÃ­vel de seguranÃ§a
        if len(risks) == 0:
            security_level = SecurityLevel.SAFE
        elif len(risks) <= 2:
            security_level = SecurityLevel.LOW_RISK
        elif len(risks) <= 4:
            security_level = SecurityLevel.MEDIUM
        else:
            security_level = SecurityLevel.HIGH
        
        return ValidationResult(
            valid=len(risks) < 5,
            security_level=security_level,
            risks=risks,
            estimated_impact="medium" if len(execution_plan) > 3 else "low",
            tests_required=True
        )
    
    def _generate_alternatives(self, user_request: str, execution_plan: List[str]) -> List[str]:
        """Gera abordagens alternativas"""
        
        prompt = f"""Sugira 2-3 abordagens alternativas para:

REQUISIÃ‡ÃƒO: "{user_request}"

PLANO ATUAL:
{json.dumps(execution_plan, indent=2)}

Liste alternativas mais seguras, mais rÃ¡pidas ou mais eficientes.
Responda como lista simples, uma alternativa por linha.
"""
        
        try:
            response = self.main_model.generate_content(prompt)
            alternatives = [line.strip() for line in response.text.split('\n') if line.strip() and not line.startswith('#')]
            return alternatives[:3]
        except:
            return []


class PteroAIUltraPro:
    """Sistema Ultra Profissional de IA - VersÃ£o 2.0"""
    
    def __init__(self, api_key: str, config_file: str = "ptero_ai_ultra_config.json"):
        print("ğŸš€ Inicializando PTERO-AI ULTRA PRO v2.0...")
        
        self.config_file = Path.home() / config_file
        self.load_config()
        
        # Cache inteligente
        cache_dir = Path(self.config['cache_path'])
        self.cache = ContextCache(cache_dir)
        
        # Motor de IA avanÃ§ado
        self.ai = SmartAIEngine(api_key, self.cache)
        
        # Contexto do sistema
        self.system_context = {}
        
        print("âœ“ Sistema inicializado com sucesso\n")
    
    def load_config(self):
        """Carrega configuraÃ§Ã£o"""
        if self.config_file.exists():
            with open(self.config_file) as f:
                self.config = json.load(f)
        else:
            self.config = {
                'ptero_path': self.detect_pterodactyl_path(),
                'backup_path': str(Path.home() / 'ptero_ultra_backups'),
                'cache_path': str(Path.home() / 'ptero_ultra_cache'),
                'safety_mode': True,
                'auto_backup': True,
                'max_backups': 100,
                'ai_confidence_threshold': 0.7,
                'require_confirmation': {
                    'critical': True,
                    'high': True,
                    'medium': True,
                    'low_risk': False,
                    'safe': False
                }
            }
            self.save_config()
        
        # Criar diretÃ³rios
        for path in ['backup_path', 'cache_path']:
            Path(self.config[path]).mkdir(parents=True, exist_ok=True)
    
    def save_config(self):
        """Salva configuraÃ§Ã£o"""
        with open(self.config_file, 'w') as f:
            json.dump(self.config, indent=2, fp=f)
    
    def detect_pterodactyl_path(self) -> str:
        """Detecta caminho do Pterodactyl"""
        paths = [
            '/var/www/pterodactyl',
            '/var/www/panel',
            '/var/www/reviactyl',
            '/var/www/pterodactyl s'
        ]
        
        for path in paths:
            if Path(path).exists() and Path(path, 'artisan').exists():
                return path
        
        return '/var/www/pterodactyl'
    
    def analyze_system(self):
        """Analisa sistema completo (versÃ£o otimizada com cache)"""
        cache_key = "full_system_analysis"
        cached = self.cache.get(cache_key)
        
        if cached:
            print("ğŸ’¾ AnÃ¡lise do sistema recuperada do cache")
            self.system_context = cached
            return
        
        print("ğŸ” Analisando sistema completo...")
        
        # AnÃ¡lise bÃ¡sica
        self.system_context = {
            'pterodactyl': {'installed': Path(self.config['ptero_path']).exists()},
            'services': [],
            'timestamp': datetime.now().isoformat()
        }
        
        self.cache.set(cache_key, self.system_context)
        print("âœ“ AnÃ¡lise concluÃ­da\n")
    
    def process_request(self, user_request: str):
        """Processa requisiÃ§Ã£o do usuÃ¡rio com inteligÃªncia ultra avanÃ§ada"""
        
        print("\n" + "=" * 70)
        print(f"ğŸ“ Processando: {user_request}")
        print("=" * 70 + "\n")
        
        # Analisar requisiÃ§Ã£o
        decision = self.ai.analyze_request(user_request, self.system_context)
        
        # Mostrar conhecimento adquirido dos arquivos
        if hasattr(self.ai, 'file_knowledge') and self.ai.file_knowledge:
            print("\nğŸ“š CONHECIMENTO DOS ARQUIVOS:")
            for file_path, analysis in self.ai.file_knowledge.items():
                deep = analysis.get('deep_analysis', {})
                score = deep.get('understanding_score', 0)
                
                print(f"\n   ğŸ“„ {Path(file_path).name}")
                print(f"      Entendimento: {score*100:.0f}%")
                print(f"      PropÃ³sito: {deep.get('purpose', 'N/A')[:80]}...")
                print(f"      Complexidade: {deep.get('complexity_level', 'N/A')}")
                
                if deep.get('key_functions'):
                    print(f"      FunÃ§Ãµes chave: {', '.join(deep['key_functions'][:3])}")
                
                if deep.get('safe_edit_zones'):
                    print(f"      âœ“ Zonas seguras: {len(deep['safe_edit_zones'])}")
                
                if deep.get('danger_zones'):
                    print(f"      âš ï¸  Zonas perigosas: {len(deep['danger_zones'])}")
        
        # Mostrar anÃ¡lise
        print("\nğŸ“Š ANÃLISE COMPLETA:")
        print(f"   AÃ§Ã£o: {decision.action}")
        print(f"   ConfianÃ§a: {decision.confidence * 100:.1f}%")
        print(f"   SeguranÃ§a: {decision.validation.security_level.value.upper()}")
        
        if decision.validation.risks:
            print(f"\nâš ï¸  RISCOS IDENTIFICADOS:")
            for risk in decision.validation.risks:
                print(f"   â€¢ {risk}")
        
        print(f"\nğŸ“‹ PLANO DE EXECUÃ‡ÃƒO ({len(decision.execution_plan)} etapas):")
        for i, step in enumerate(decision.execution_plan, 1):
            print(f"   {i}. {step}")
        
        if decision.alternatives:
            print(f"\nğŸ’¡ ALTERNATIVAS:")
            for i, alt in enumerate(decision.alternatives, 1):
                print(f"   {i}. {alt}")
        
        # Verificar se requer confirmaÃ§Ã£o
        security_level = decision.validation.security_level.value
        requires_confirmation = self.config['require_confirmation'].get(security_level, True)
        
        if requires_confirmation:
            print(f"\nâš¡ Esta operaÃ§Ã£o requer confirmaÃ§Ã£o ({security_level})")
            response = input("   Executar? (s/n/dry): ").lower().strip()
            
            if response == 'dry':
                print("\nğŸ§ª Modo DRY-RUN ativado (simulaÃ§Ã£o)")
                self._simulate_execution(decision)
                return
            elif response != 's':
                print("\nâŒ OperaÃ§Ã£o cancelada")
                return
        
        print("\nğŸš€ Executando...")
        # Aqui implementaria a execuÃ§Ã£o real
        print("âœ“ OperaÃ§Ã£o completada\n")
    
    def chat(self, user_message: str) -> str:
        """Modo chat simples sem confirmaÃ§Ãµes (para interface grÃ¡fica)"""
        try:
            # Usar o main_model para responder
            response = self.ai.main_model.generate_content(
                f"VocÃª Ã© PTERO-AI Ultra Pro, um assistente especializado em Pterodactyl Panel.\n\n"
                f"UsuÃ¡rio: {user_message}\n\n"
                f"Responda de forma Ãºtil e amigÃ¡vel. Se for sobre Pterodactyl, seja especÃ­fico. "
                f"Se for uma saudaÃ§Ã£o, seja breve e pergunte como pode ajudar."
            )
            
            return response.text
        except Exception as e:
            return f"âŒ Erro ao processar: {str(e)}"
    
    def _simulate_execution(self, decision: AIDecision):
        """Simula execuÃ§Ã£o sem aplicar mudanÃ§as"""
        print("\nğŸ§ª SIMULAÃ‡ÃƒO DE EXECUÃ‡ÃƒO:\n")
        
        for i, step in enumerate(decision.execution_plan, 1):
            print(f"   [{i}/{len(decision.execution_plan)}] {step}")
            time.sleep(0.3)  # Simular tempo de processamento
            print(f"       âœ“ Simulado com sucesso")
        
        print("\nâœ“ SimulaÃ§Ã£o completa - Nenhuma mudanÃ§a foi aplicada")
    
    def interactive_mode(self):
        """Modo interativo ultra inteligente"""
        
        print("\n" + "=" * 70)
        print("ğŸ¤– PTERO-AI ULTRA PRO v2.0 - Modo Interativo")
        print("=" * 70)
        print("\nSistema de IA Multi-Camadas com InteligÃªncia AvanÃ§ada")
        print("\nComandos:")
        print("  analyze  - AnÃ¡lise completa do sistema")
        print("  status   - Status atual")
        print("  history  - HistÃ³rico de decisÃµes")
        print("  config   - Ver/editar configuraÃ§Ã£o")
        print("  exit     - Sair")
        print("\nOu converse naturalmente sobre qualquer coisa!")
        print("=" * 70 + "\n")
        
        # AnÃ¡lise inicial
        self.analyze_system()
        
        while True:
            try:
                user_input = input("\nğŸ’¬ VocÃª: ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() == 'exit':
                    print("\nğŸ‘‹ AtÃ© logo!")
                    break
                
                elif user_input.lower() == 'analyze':
                    self.cache.memory.clear()  # Limpar cache para nova anÃ¡lise
                    self.analyze_system()
                    continue
                
                elif user_input.lower() == 'history':
                    print("\nğŸ“œ HISTÃ“RICO DE DECISÃ•ES:")
                    for i, entry in enumerate(self.ai.decision_history[-10:], 1):
                        print(f"\n{i}. [{entry['timestamp']}]")
                        print(f"   RequisiÃ§Ã£o: {entry['request']}")
                        print(f"   AÃ§Ã£o: {entry['decision']['action']}")
                    continue
                
                elif user_input.lower() == 'config':
                    print(json.dumps(self.config, indent=2))
                    continue
                
                # Processar requisiÃ§Ã£o
                self.process_request(user_input)
                
            except KeyboardInterrupt:
                print("\n\nâš ï¸  InterrupÃ§Ã£o detectada")
                break
            except Exception as e:
                print(f"\nâŒ Erro: {e}")
                import traceback
                traceback.print_exc()


def main():
    """FunÃ§Ã£o principal"""
    
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                          â•‘
    â•‘         ğŸš€ PTERO-AI ULTRA PRO v2.0 ğŸš€                    â•‘
    â•‘                                                          â•‘
    â•‘      Sistema de IA Multi-Camadas                        â•‘
    â•‘      com InteligÃªncia AvanÃ§ada                          â•‘
    â•‘                                                          â•‘
    â•‘  âœ“ 5 Camadas de ValidaÃ§Ã£o                               â•‘
    â•‘  âœ“ Cache Inteligente de Contexto                        â•‘
    â•‘  âœ“ AnÃ¡lise Multi-Modelo                                 â•‘
    â•‘  âœ“ Sistema de Scores de SeguranÃ§a                       â•‘
    â•‘  âœ“ GeraÃ§Ã£o de Alternativas                              â•‘
    â•‘  âœ“ HistÃ³rico de DecisÃµes                                â•‘
    â•‘                                                          â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # API Key
    api_key = "AIzaSyDJ6V-x0EP0vGVaJ4n7mGFSOBSy2EDZIRg"
    
    try:
        ai = PteroAIUltraPro(api_key)
        ai.interactive_mode()
    except Exception as e:
        print(f"\nâŒ Erro crÃ­tico: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
